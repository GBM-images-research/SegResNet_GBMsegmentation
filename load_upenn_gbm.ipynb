{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.25.0\n",
      "Pytorch version: 2.0.1+cpu\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: c:\\Users\\Cecilia\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\unsup-seg-gbm-nLgqUjZ0-py3.11\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 10.0.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.5\n",
      "pandas version: 2.0.3\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.apps import DecathlonDataset, TciaDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    "    ResampleToMatchd,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Decatlon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is necrosis\n",
    "    label 2 is edema\n",
    "    label 3 is activo\n",
    "    The possible classes are N (necrosis), E (edema)\n",
    "    and TA (active).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # label 1 necro\n",
    "            result.append(d[key] == 1)\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 2)\n",
    "            # merge labels 3, 4 and 3 to construct activo\n",
    "            result.append(torch.logical_or(d[key] == 3, d[key] == 4))\n",
    "\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"],allow_missing_keys=True),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we don't cache any data in case out of memory issue\n",
    "root_dir=\"./Dataset\"\n",
    "train_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=train_transform,\n",
    "    section=\"training\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
    "val_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=val_transform,\n",
    "    section=\"validation\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=4,\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 240, 240, 155])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        #LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        #ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        #Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "        #NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images and 2 labels.\n",
      "Image files: [['./Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00011_11\\\\UPENN-GBM-00011_11_DSC_ap-rCBV.nii.gz', './Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00011_11\\\\UPENN-GBM-00011_11_DSC_PH.nii.gz', './Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00011_11\\\\UPENN-GBM-00011_11_DSC_PSR.nii.gz'], ['./Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00012_11\\\\UPENN-GBM-00012_11_DSC_ap-rCBV.nii.gz', './Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00012_11\\\\UPENN-GBM-00012_11_DSC_PH.nii.gz', './Dataset/Custom_dataset_1/valid\\\\images\\\\images_DSC\\\\UPENN-GBM-00012_11\\\\UPENN-GBM-00012_11_DSC_PSR.nii.gz']]\n",
      "Label files: ['./Dataset/Custom_dataset_1/valid\\\\labels\\\\UPENN-GBM-00011_11_automated_approx_segm.nii.gz', './Dataset/Custom_dataset_1/valid\\\\labels\\\\UPENN-GBM-00012_11_automated_approx_segm.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "from src.get_data import CustomDataset\n",
    "\n",
    "val=CustomDataset('./Dataset/Custom_dataset_1/', section=\"valid\", transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 240, 240, 155])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import LoadImaged, Compose\n",
    "from src.get_data import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        #ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 images and 10 labels.\n"
     ]
    }
   ],
   "source": [
    "# Define your data transformations using MONAI transforms.\n",
    "# Example: You can add more transforms based on your requirements.\n",
    "#transform = Compose([YourOtherTransformsHere])\n",
    "\n",
    "# Create instances of your custom dataset for training and validation.\n",
    "train_dataset = CustomDataset(root_dir='E:\\\\Download\\\\UPENN-GBM\\\\Custom_dataset\\\\train', transform=transform)\n",
    "#valid_dataset = CustomDataset(root_dir='path/to/valid', transform=transform)\n",
    "\n",
    "# Create data loaders using the datasets.\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "#valid_loader = DataLoader(valid_dataset, batch_size=your_batch_size, shuffle=False, num_workers=your_num_workers)\n",
    "\n",
    "# Access images and labels from the dataset\n",
    "#sample = train_dataset[0]\n",
    "#print(sample[\"image\"], sample[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Alexander\\1_Doctorado\\Software\\Unsup_seg_GBM\\load_upenn_gbm.ipynb Celda 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Alexander/1_Doctorado/Software/Unsup_seg_GBM/load_upenn_gbm.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset\u001b[39m.\u001b[39mlabel_files[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Alexander/1_Doctorado/Software/Unsup_seg_GBM/load_upenn_gbm.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_loader[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_dataset.label_files[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsup-seg-gbm-nLgqUjZ0-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
